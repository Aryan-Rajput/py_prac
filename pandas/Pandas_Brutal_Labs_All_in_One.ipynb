{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Pandas Brutal Labs — All-in-One (70 Labs + Electrical Madness + Frog Puzzles)\n",
    "\n",
    "**How to use:** Run the Setup cell first. Each Lab has a short goal and runnable solution. \n",
    "The puzzles (Electrical Madness & Frog) are implemented using Pandas operations like `shift`, `merge`, `groupby`.\n",
    "\n",
    "**Tip:** Prefer vectorized Pandas/Numpy ops over Python loops. Use `astype`, `to_datetime`, `merge`, `groupby`, `agg`, `apply` (sparingly), `explode`, `stack/unstack`, `pivot`, `melt`, and `Categorical` wisely.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 3.0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re #re: Python’s regex engine—useful for string cleaning and pattern extraction.\n",
    "import time \n",
    "# Measuring durations (time.perf_counter())\n",
    "# For more precise timing in data workflows, prefer time.perf_counter() over time.time().\n",
    "pd.set_option('display.width', 120)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "def seed(n=42):\n",
    "    np.random.seed(n)\n",
    "# This is a simple convenience wrapper so seed() sets NumPy’s global RNG state.\n",
    "# Calling seed(42) means all subsequent np.random.* calls (e.g., randn, permutation, choice) become reproducible.\n",
    "\n",
    "print('pandas:', pd.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 1: DataFrame from two-dimensional list\n",
    "**Goals:** Create DF, set columns, dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id         Int64\n",
      "name      string\n",
      "score    float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bob</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cara</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   name  score\n",
       "0   1  Alice   10.5\n",
       "1   2    Bob   20.0\n",
       "2   3   Cara   15.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed(42) # not much use here\n",
    "# print(seed.__doc__)\n",
    "# print(seed(42))\n",
    "#  this seed(42) is to ensure reproducibility as it sets the random number generator to a fixed state\n",
    "data = [\n",
    "    [1, \"Alice\", 10.5],\n",
    "    [2, \"Bob\",   20.0],\n",
    "    [3, \"Cara\",  15.2],\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data,\n",
    "    columns=['id','name','score']\n",
    ").astype({\n",
    "    'id':    'Int64',   # pandas nullable integer type\n",
    "    'name':  'string',  # pandas string type\n",
    "    'score': 'float64'  # standard float type\n",
    "})\n",
    "\n",
    "print(df.dtypes)\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 2: From dict of arrays/lists\n",
    "**Goals:** Align lengths, dtype inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id name  score\n",
      "0   1    A   10.0\n",
      "1   2    B   20.0\n",
      "2   3    C   30.0\n",
      "   name  score\n",
      "id            \n",
      "1     A   10.0\n",
      "2     B   20.0\n",
      "3     C   30.0\n"
     ]
    }
   ],
   "source": [
    "# << 1 >>\n",
    "# Pandas builds columns column-wise (not row-wise like in Lab 1).\n",
    "# Column order follows dict insertion order (Python 3.7+ guarantees it), so the final column order will be: id, name, score.\n",
    "\n",
    "# << 2 >> \n",
    "# You didn’t provide an index ---> Pandas creates a default RangeIndex(0, 3).\n",
    "# So rows are 0, 1, 2.\n",
    "\n",
    "# << 3 >> \n",
    "# id: [1, 2, 3] ---> all ints ---> inferred as int64 (platform dependent, but typically 64-bit).\n",
    "# name: ['A', 'B', 'C'] ---> Python strings ---> inferred as object dtype (i.e., references to Python str objects).\n",
    "# score: np.array([10.0, 20.0, 30.0]) ---> a NumPy array of floats ---> stays float64.\n",
    "\n",
    "\n",
    "\"\"\" << -+---------------------------+- >> \"\"\"\n",
    "\n",
    "# Pandas is happy with either a list or a NumPy array; dtype inference would still arrive at float64 here.\n",
    "# Where it matters:\n",
    "\n",
    "# Performance/Copy behavior: If you pass a NumPy array, Pandas may avoid copying in some cases (constructor tries to be zero-copy when safe). Lists always need conversion.\n",
    "# Dtype control: NumPy arrays already have a dtype; Pandas will respect it unless it must cast (e.g., mixing with incompatible values).\n",
    "# example ==> forcing a specific dtype via NumPy\n",
    "\n",
    "# np.array([10, 20, 30], dtype=np.float32)  # yields float32\n",
    "# Pandas will typically keep float32 for the column rather than upcasting to float64\n",
    "\n",
    "\"\"\" << -+---------------------------+- >> \"\"\"\n",
    "\n",
    "# --> name becomes object, not “string dtype”\n",
    "\n",
    "# By default, Pandas uses object for text columns (backed by Python str objects).\n",
    "# If you need consistent missing semantics (<NA>), better vectorized string ops, and sometimes memory wins, convert to the dedicated string dtype:\n",
    "\n",
    "\n",
    "# --> Nullable integers vs plain integers\n",
    "\n",
    "# int64 cannot represent missing values. If later you insert NaN into id, Pandas will upcast the entire column to float64 (e.g., 1 → 1.0).\n",
    "# If id may have missing values, use nullable Int64 (capital I): df = df.astype({'id': 'Int64'})\n",
    "\n",
    "\n",
    "\"\"\" << -+- ORIGNAL CODE -+- >> \"\"\"\n",
    "\n",
    "df = pd.DataFrame({'id':[1,2,3], 'name':['A','B','C'], 'score':np.array([10.0,20.0,30.0])})\n",
    "print(df)\n",
    "\n",
    "\n",
    "\"\"\" << -+- VARIATIONS -+- >> \"\"\"\n",
    "\n",
    "    \"\"\" << -+- 1 -+- >> \"\"\"\n",
    "# so for a improvemennt we can use id as an index by suign set_index\n",
    "df = df.set_index('id')\n",
    "print(df)\n",
    "\n",
    "    \"\"\" << -+- 2 -+- >> \"\"\"\n",
    "# Use better text dtype and nullable ints right away\n",
    "# df = (pd.DataFrame({'id':[1,2,3], 'name':['A','B','C'], 'score':[10.0,20.0,30.0]})\n",
    "#         .astype({'id': 'Int64', 'name': 'string', 'score': 'float64'}))\n",
    "\n",
    "# BUT SINCE WE ALREADY MADE DF WE CAN JUST DO\n",
    "df = df.astype({'id': 'Int64', 'name': 'string', 'score': 'float64'})\n",
    "print(df)\n",
    "\n",
    "    \"\"\" << -+- 3 -+- >> \"\"\"\n",
    "# Using NumPy array with specific dtype\n",
    "df = pd.DataFrame({\n",
    "    'id':   np.array([1,2,3], dtype=np.int32),\n",
    "    'name': np.array(['A','B','C'], dtype='U10'),\n",
    "    'score':np.array([10.0,20.0,30.0], dtype=np.float32)\n",
    "})\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 3: From list of lists with columns\n",
    "**Goals:** Assign column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2420110864.py, line 9)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m\"\"\" << -+- 1 -+- >> \"\"\"\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\" << -+- ORIGNAL CODE -+- >> \"\"\"\n",
    "rows = [[101,'x'],[102,'y']]\n",
    "# When to use category\n",
    "# If dept has low cardinality and repeats a lot (e.g., 'HR', 'ENG', 'FIN'), categoricals save memory and speed up group-bys:\n",
    "df = pd.DataFrame(rows, columns=['emp_id','dept'])\n",
    "\n",
    "\"\"\" << -+- ITERATIONS -+- >> \"\"\"\n",
    "\"\"\" << -+- ----------------------------------- -+- >> \"\"\"\n",
    "\"\"\" << -+- 1 -+- >> \"\"\"\n",
    "# USING CATEGORIES IN VALUES THAT HAVE A LOW CARDINALITY\n",
    "# TERMONLOGY: Cardinality = number of unique values in a column. Low cardinality means few unique values relative to total rows.\n",
    "# Example: dept with values like 'HR', 'ENG', 'FIN' repeated across many rows has low cardinality, while a column like 'emp_id'\n",
    "#    with unique values for each employee has high cardinality.\n",
    "# Categorical dtype is ideal for low-cardinality columns because it stores data as integer codes with a separate mapping to the actual \n",
    "#   category values, which can save memory and speed up operations like group-bys and comparisons.\n",
    "\n",
    "# Categories list (unique values)\n",
    "# -- ['x', 'y']\n",
    "\n",
    "# 2. Codes (integer mapping for each row)\n",
    "# -- 0, 1, 0, 0, 1, 0, 1, ...\n",
    "\n",
    "# So instead of storing strings repeatedly, Pandas stores:\n",
    "# -- 2 strings: 'x' and 'y'\n",
    "# -- an integer array for the data         # Huge efficiency win.\n",
    "\n",
    "df['dept'] = df['dept'].astype('category')\n",
    "print(df)\n",
    "\n",
    "\"\"\" << -+- ----------------------------------- -+- >> \"\"\"\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 4: From list of tuples\n",
    "**Goals:** Tuple rows behave like lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows = [(1,'p'),(2,'q')]\n",
    "df = pd.DataFrame(rows, columns=['k','v'])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 5: From list of dicts\n",
    "**Goals:** Heterogeneous keys → columns union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows = [{'id':1,'name':'A'},{'id':2,'name':'B','city':'NY'}]\n",
    "df = pd.DataFrame(rows)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 6: From nested dict (outer keys → columns or index)\n",
    "**Goals:** Normalize nested dict to columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nested = {'r1':{'a':1,'b':2}, 'r2':{'a':3,'b':4,'c':5}}\n",
    "df = pd.DataFrame.from_dict(nested, orient='index').reset_index(names='row')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 7: From Series\n",
    "**Goals:** Series → single-column or to_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s = pd.Series([10,20,30], index=['x','y','z'], name='value')\n",
    "df = s.to_frame()\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 8: Construct from string data\n",
    "**Goals:** Convert object→numeric, errors handling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'raw':['  10','20 ',' NotANumber ','30']})\n",
    "df['raw_clean'] = df['raw'].str.strip()\n",
    "df['num'] = pd.to_numeric(df['raw_clean'], errors='coerce')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 9: Clean string data\n",
    "**Goals:** strip/lower/replace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'name':['  Alice ','BoB','cARA  ']})\n",
    "df['norm'] = df['name'].str.strip().str.lower()\n",
    "df['alpha'] = df['norm'].str.replace(r'[^a-z]','', regex=True)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 10: Replace using regex\n",
    "**Goals:** Regex patterns with `replace`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'txt':['A-123','B_456','C 789']})\n",
    "df['digits'] = df['txt'].str.replace(r'\\D+','', regex=True)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 11: Reindexing\n",
    "**Goals:** Create new index with fill\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'v':[1,2,3]}, index=[2,4,6])\n",
    "print('orig\n",
    "', df)\n",
    "print('reindexed\n",
    "', df.reindex([1,2,3,4,5,6], fill_value=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 12: Map external values (Series.map)\n",
    "**Goals:** Category → code mapping, missing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'tier':['gold','silver','bronze','platinum']})\n",
    "mp = {'bronze':1,'silver':2,'gold':3}\n",
    "df['code'] = df['tier'].map(mp)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 13: Reset index\n",
    "**Goals:** `reset_index(drop=True)` vs keep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'a':[1,2,3]}, index=['x','y','z'])\n",
    "print(df.reset_index())\n",
    "print(df.reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 14: Rename columns & index\n",
    "**Goals:** `rename` with dict, `set_axis`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'A':[1,2],'B':[3,4]}, index=['r1','r2'])\n",
    "print(df.rename(columns={'A':'alpha'}, index={'r1':'row1'}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 15: Map a column with dict (missing handling)\n",
    "**Goals:** `map` vs `fillna`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'dept':['ENG','FIN','HR','OPS']})\n",
    "lookup = {'ENG':'Engineering','FIN':'Finance','HR':'HR'}\n",
    "df['dept_full'] = df['dept'].map(lookup).fillna('Unknown')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 16: map() vs replace()\n",
    "**Goals:** `map` for transformation; `replace` for direct substitution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'x':['A','B','C','D']})\n",
    "print('map:')\n",
    "print(df['x'].map({'A':1,'B':2}))\n",
    "print('replace:')\n",
    "print(df['x'].replace({'A':1,'B':2}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 17: DataFrame.map / applymap fallback\n",
    "**Goals:** Elementwise function over entire DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame([[1,2],[3,4]], columns=['a','b'])\n",
    "# Pandas provides DataFrame.applymap; DataFrame.map may exist in newer versions. Use applymap here.\n",
    "df2 = df.applymap(lambda v: v*v)\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 18: from_dict & to_dict\n",
    "**Goals:** records/index/list/orient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows = [{'id':1,'name':'A'},{'id':2,'name':'B'}]\n",
    "df = pd.DataFrame.from_dict(rows)\n",
    "print('records -> df:\n",
    "', df)\n",
    "print('to_dict records:\n",
    "', df.to_dict(orient='records'))\n",
    "print('to_dict index:\n",
    "', df.set_index('id').to_dict(orient='index'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 19: Multicolumn mapping\n",
    "**Goals:** map two columns using two lookups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'dept':['ENG','FIN','ENG'], 'level':[1,2,2]})\n",
    "mp_dept={'ENG':'Engineering','FIN':'Finance'}\n",
    "mp_level={1:'L1',2:'L2'}\n",
    "df['dept_full'] = df['dept'].map(mp_dept)\n",
    "df['level_str'] = df['level'].map(mp_level)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 20: Nested dictionaries mapping\n",
    "**Goals:** map (dept,level) → title using tuple key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'dept':['ENG','ENG','FIN'], 'level':[1,2,2]})\n",
    "mp = {('ENG',1):'SWE I', ('ENG',2):'SWE II', ('FIN',2):'Analyst II'}\n",
    "df['title'] = list(map(lambda t: mp.get((t[0], t[1]), 'NA'), df[['dept','level']].itertuples(index=False, name=None)))\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 21: Iterate over rows (iterrows)\n",
    "**Goals:** Education-only; avoid for perf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'x':[1,2],'y':[3,4]})\n",
    "for i, row in df.iterrows():\n",
    "    print(i, row['x'] + row['y'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 22: Row iteration with itertuples\n",
    "**Goals:** Faster than iterrows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'x':[1,2],'y':[3,4]})\n",
    "for r in df.itertuples(index=True, name='Row'):\n",
    "    print(r.Index, r.x + r.y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 23: Selecting rows by conditions\n",
    "**Goals:** Boolean masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'name':['Ann','Ben','Cara','Dee'], 'age':[17,20,21,18]})\n",
    "print(df[df['age']>=18])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 24: Select any row using iloc[] and iat[]\n",
    "**Goals:** Position-based access\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'a':[10,20,30]})\n",
    "print(df.iloc[1])\n",
    "print(df.iat[2,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 25: Limited rows with given columns\n",
    "**Goals:** Slice rows/cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'a':[1,2,3],'b':[4,5,6],'c':[7,8,9]})\n",
    "print(df.loc[0:1, ['a','c']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 26: Drop rows on condition\n",
    "**Goals:** `drop` with mask index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'a':[1,2,3,4]})\n",
    "df = df.drop(df[df['a']%2==0].index)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 27: Insert row at position\n",
    "**Goals:** Use concat; reindex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'a':[1,3,4]})\n",
    "row = pd.DataFrame({'a':[2]})\n",
    "df2 = pd.concat([df.iloc[:1], row, df.iloc[1:]], ignore_index=True)\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 28: Create list from rows\n",
    "**Goals:** records/tuples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'id':[1,2],'name':['A','B']})\n",
    "print(df.to_dict('records'))\n",
    "print(list(df.itertuples(index=False, name=None)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 29: Ranking rows\n",
    "**Goals:** `rank` methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'name':['A','B','C','D'],'score':[90,95,90,80]})\n",
    "df['rank_dense'] = df['score'].rank(method='dense', ascending=False).astype(int)\n",
    "print(df.sort_values('rank_dense'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 30: Sorting rows\n",
    "**Goals:** Single/multi column sort\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'a':[2,1,2],'b':[3,2,1]})\n",
    "print(df.sort_values(['a','b'], ascending=[True, False]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 31: Row with max/min value\n",
    "**Goals:** idxmax/idxmin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'x':[5,9,3],'y':[7,1,8]})\n",
    "print('row of max x:\n",
    "', df.loc[[df['x'].idxmax()]])\n",
    "print('row of min y:\n",
    "', df.loc[[df['y'].idxmin()]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 32: Rows containing substring\n",
    "**Goals:** `str.contains`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'text':['foo bar','lorem','barista']})\n",
    "print(df[df['text'].str.contains('bar')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 33: Convert column to index\n",
    "**Goals:** `set_index`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'id':[1,2],'val':[10,20]})\n",
    "print(df.set_index('id'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 34: Randomly select rows\n",
    "**Goals:** `sample`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'a':range(10)})\n",
    "print(df.sample(3, random_state=42))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 35: Create column (vectorized instead of for-loop)\n",
    "**Goals:** Avoid Python loops; use vectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'a':[1,2,3],'b':[10,20,30]})\n",
    "# Vectorized:\n",
    "df['c'] = df['a']*df['b']\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 36: Get column names\n",
    "**Goals:** `df.columns`, list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'x':[1],'y':[2]})\n",
    "print(list(df.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 37: Rename columns\n",
    "**Goals:** `rename` or `set_axis`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'A':[1],'B':[2]})\n",
    "print(df.rename(columns={'A':'alpha'}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 38: Unique values from column\n",
    "**Goals:** `unique`, `nunique`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'c':['a','b','a','c']})\n",
    "print(df['c'].unique())\n",
    "print(df['c'].nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 39: Conditional operation columns\n",
    "**Goals:** `np.where`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'x':[1,2,3,4]})\n",
    "df['parity'] = np.where(df['x']%2==0, 'even', 'odd')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 40: Return index labels where condition\n",
    "**Goals:** `index[mask]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'x':[5,1,5,2]})\n",
    "mask = df['x']==5\n",
    "print(df.index[mask].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 41: Formatting integer column\n",
    "**Goals:** string formatting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'acct':[1,23,456]})\n",
    "df['acct_str'] = df['acct'].map(lambda v: f\"ACC-{v:04d}\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 42: New column from existing\n",
    "**Goals:** combine columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'first':['A','B'],'last':['x','y']})\n",
    "df['user'] = df['first'].str.lower() + '_' + df['last']\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 43: Column from condition\n",
    "**Goals:** chain conditions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'score':[35,60,85]})\n",
    "conds = [df['score']<50, df['score'].between(50,79), df['score']>=80]\n",
    "vals = ['fail','pass','distinction']\n",
    "df['grade'] = np.select(conds, vals, default='NA')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 44: Split string into columns (regex)\n",
    "**Goals:** `str.extract` / `str.split(expand=True)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'raw':['A-12','B_34','C 56']})\n",
    "print(df['raw'].str.extract(r'(?P<letter>[A-Z])\\D*(?P<num>\\d+)'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 45: Frequency counts\n",
    "**Goals:** `value_counts`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'c':['a','b','a','c','a']})\n",
    "print(df['c'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 46: Split a text column into two\n",
    "**Goals:** `str.split(expand=True, n=1)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'name':['Last, First','Doe, Jane']})\n",
    "last_first = df['name'].str.split(',', n=1, expand=True)\n",
    "last_first.columns=['last','first']\n",
    "print(last_first)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 47: Index of min value\n",
    "**Goals:** `idxmin`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'v':[5,3,7,1,9]})\n",
    "print(df['v'].idxmin())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 48: Index of max value\n",
    "**Goals:** `idxmax`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'v':[5,3,7,1,9]})\n",
    "print(df['v'].idxmax())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 49: Difference of two columns\n",
    "**Goals:** Vectorized subtraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'a':[10,20],'b':[3,8]})\n",
    "df['diff'] = df['a'] - df['b']\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 50: n-largest values from a column\n",
    "**Goals:** `nlargest`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'x':[5,1,9,7,3]})\n",
    "print(df['x'].nlargest(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 51: n-smallest values from a column\n",
    "**Goals:** `nsmallest`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'x':[5,1,9,7,3]})\n",
    "print(df['x'].nsmallest(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 52: Drop one/multiple columns\n",
    "**Goals:** `drop(columns=...)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'a':[1],'b':[2],'c':[3]})\n",
    "print(df.drop(columns=['b','c']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 53: Lowercase column names\n",
    "**Goals:** rename with comprehension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'First Name':[1], 'LAST_NAME':[2]})\n",
    "df.columns = [c.lower() for c in df.columns]\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 54: Capitalize first letter of a column\n",
    "**Goals:** `str.title` or custom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'city':['new york','san francisco']})\n",
    "print(df['city'].str.title())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 55: Uppercase a column\n",
    "**Goals:** `str.upper`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'code':['ab','Cd']})\n",
    "print(df['code'].str.upper())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 56: Basics of Time Series Manipulation\n",
    "**Goals:** `to_datetime`, set index, sort_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'ts':['2023-01-01','2023-01-03','2023-01-02'], 'v':[1,3,2]})\n",
    "df['ts'] = pd.to_datetime(df['ts'])\n",
    "df = df.set_index('ts').sort_index()\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 57: Timedelta & Period indexes\n",
    "**Goals:** `pd.timedelta_range`, `pd.period_range`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(pd.timedelta_range('0 days', periods=3, freq='2H'))\n",
    "print(pd.period_range('2024-01', periods=3, freq='M'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 58: Convert string column → datetime\n",
    "**Goals:** `to_datetime(errors='coerce')`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'when':['2024/01/01','bad','2024-03-05']})\n",
    "df['ts'] = pd.to_datetime(df['when'], errors='coerce')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 59: Electrical Madness I — 2D Potential via DataFrame.shift\n",
    "**Goals:** Stencil Jacobi update using df.shift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N=16\n",
    "V = pd.DataFrame(np.zeros((N,N)))\n",
    "V.iloc[0,:] = 1.0   # top 1V, others 0V\n",
    "for _ in range(200):\n",
    "    avg = (V.shift(1, axis=0).fillna(0) + V.shift(-1, axis=0).fillna(0) +\n",
    "           V.shift(1, axis=1).fillna(0) + V.shift(-1, axis=1).fillna(0)) / 4.0\n",
    "    V.iloc[1:-1,1:-1] = avg.iloc[1:-1,1:-1]\n",
    "    V.iloc[0,:] = 1.0; V.iloc[-1,:]=0.0; V.iloc[:,0]=0.0; V.iloc[:,-1]=0.0\n",
    "print(round(float(V.iloc[N//2, N//2]), 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 60: Electrical Madness II — Discrete Laplacian in Pandas\n",
    "**Goals:** Use shifts to compute Laplacian residual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N=16\n",
    "V = pd.DataFrame(np.zeros((N,N)))\n",
    "V.iloc[0,:] = 1.0\n",
    "for _ in range(300):\n",
    "    up=V.shift(1,0).fillna(0); dn=V.shift(-1,0).fillna(0)\n",
    "    lf=V.shift(1,1).fillna(0); rt=V.shift(-1,1).fillna(0)\n",
    "    R = (up+dn+lf+rt - 4*V)\n",
    "    V = V + 0.25*R\n",
    "    V.iloc[0,:] = 1.0; V.iloc[-1,:]=0.0; V.iloc[:,0]=0.0; V.iloc[:,-1]=0.0\n",
    "print(V.iloc[:3,:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 61: Electrical Madness III — Graph Laplacian with DataFrames\n",
    "**Goals:** Edges DataFrame → Laplacian via groupby\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build 3x3 grid nodes and edges; compute degree and Laplacian matrix using groupby\n",
    "n=3; m=3\n",
    "nodes = [(i*m+j) for i in range(n) for j in range(m)]\n",
    "edges=[]\n",
    "for i in range(n):\n",
    "    for j in range(m):\n",
    "        u=i*m+j\n",
    "        for di,dj in [(1,0),(0,1)]:\n",
    "            ii, jj = i+di, j+dj\n",
    "            if 0<=ii<n and 0<=jj<m:\n",
    "                v=ii*m+jj; edges.append((u,v))\n",
    "E = pd.DataFrame(edges, columns=['u','v'])\n",
    "# Undirected add reverse\n",
    "E = pd.concat([E, E.rename(columns={'u':'v','v':'u'})], ignore_index=True)\n",
    "# Degree\n",
    "deg = E.groupby('u').size().rename('deg')\n",
    "L = pd.DataFrame(0, index=nodes, columns=nodes)\n",
    "for _,row in E.iterrows():\n",
    "    L.loc[row.u, row.v] -= 1\n",
    "for k,d in deg.items():\n",
    "    L.loc[k,k] = d\n",
    "print(L)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 62: Frog I — 2D Knight Moves via merge\n",
    "**Goals:** Frontier positions as DataFrame; next via vectorized merge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N=8\n",
    "moves = pd.DataFrame([(-2,-1),(-2,1),(-1,-2),(-1,2),(1,-2),(1,2),(2,-1),(2,1)], columns=['dr','dc'])\n",
    "front = pd.DataFrame({'r':[0],'c':[0]})\n",
    "seen = front.copy()\n",
    "for step in range(1,8):\n",
    "    cand = front.assign(key=1).merge(moves.assign(key=1), on='key').drop('key',axis=1)\n",
    "    cand['r']=cand['r']+cand['dr']; cand['c']=cand['c']+cand['dc']\n",
    "    cand = cand[(cand['r'].between(0,N-1)) & (cand['c'].between(0,N-1))]\n",
    "    front = cand[['r','c']].drop_duplicates().merge(seen, on=['r','c'], how='left', indicator=True)\n",
    "    front = front[front['_merge']=='left_only'][['r','c']]\n",
    "    seen = pd.concat([seen, front]).drop_duplicates()\n",
    "print('reachable cells:', len(seen))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 63: Frog II — 3D Levels + Teleports\n",
    "**Goals:** Use DataFrames for (level,row,col) transitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "L,R,C = 3,6,6\n",
    "front = pd.DataFrame({'l':[0],'r':[0],'c':[0]})\n",
    "seen = front.copy()\n",
    "steps2d = pd.DataFrame([(-1,0),(1,0),(0,-1),(0,1)], columns=['dr','dc'])\n",
    "tele = pd.DataFrame([(1,0,0),(-1,0,0)], columns=['dl','dr','dc'])\n",
    "for step in range(1,10):\n",
    "    cand2d = front.assign(key=1).merge(steps2d.assign(key=1), on='key').drop('key',1)\n",
    "    cand2d['l']=front['l'].values.repeat(len(steps2d))\n",
    "    cand2d['r']=cand2d['r']+cand2d['dr']; cand2d['c']=cand2d['c']+cand2d['dc']; cand2d['dl']=0\n",
    "    candt = front.assign(key=1).merge(tele.assign(key=1), on='key').drop('key',1)\n",
    "    candt['l']=candt['l']+candt['dl']; candt['r']=candt['r']+candt['dr']; candt['c']=candt['c']+candt['dc']\n",
    "    cand = pd.concat([cand2d[['l','r','c']], candt[['l','r','c']]])\n",
    "    cand = cand[cand['l'].between(0,L-1) & cand['r'].between(0,R-1) & cand['c'].between(0,C-1)]\n",
    "    front = cand.drop_duplicates().merge(seen, on=['l','r','c'], how='left', indicator=True)\n",
    "    front = front[front['_merge']=='left_only'][['l','r','c']]\n",
    "    seen = pd.concat([seen, front]).drop_duplicates()\n",
    "print('reachable states:', len(seen))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 64: Second Highest Salary\n",
    "**Goals:** Drop duplicates then nlargest(2).tail(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'salary':[100,200,200,300,150]})\n",
    "unique = df['salary'].drop_duplicates().nlargest(2)\n",
    "second = unique.iloc[-1] if len(unique)>=2 else None\n",
    "print(second)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 65: Rank Scores\n",
    "**Goals:** dense rank descending\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'name':['A','B','C','D'],'score':[90,95,90,80]})\n",
    "df['rank'] = df['score'].rank(method='dense', ascending=False).astype(int)\n",
    "print(df.sort_values(['rank','name']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 66: Invalid Comments (regex)\n",
    "**Goals:** Keep only alnum & space; flag invalid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'c':['ok comment','bad@@@','another#no']})\n",
    "df['valid'] = ~df['c'].str.contains(r'[^\\w\\s]', regex=True)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 67: Salesperson Without Orders to Company (anti-join)\n",
    "**Goals:** left_anti merge pattern\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sales = pd.DataFrame({'sid':[1,2,3],'cust':['A','B','C']})\n",
    "orders = pd.DataFrame({'sid':[1,1,3],'company':['CorpX','CorpY','CorpX']})\n",
    "# Want salespeople with no orders to CorpX\n",
    "corpX = orders[orders['company']=='CorpX'][['sid']].drop_duplicates()\n",
    "anti = sales.merge(corpX, on='sid', how='left', indicator=True)\n",
    "print(anti[anti['_merge']=='left_only'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 68: Unique Projects by Employee\n",
    "**Goals:** groupby agg(set) + explode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'emp':[1,1,2,2,2],'proj':['P1','P1','P2','P1','P3']})\n",
    "agg = df.groupby('emp')['proj'].unique().rename('projects').reset_index()\n",
    "print(agg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 69: Salary Trends Across Departments\n",
    "**Goals:** groupby over time; rolling mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed(42)\n",
    "dates = pd.date_range('2023-01-01', periods=6, freq='M')\n",
    "df = pd.DataFrame({'date':np.repeat(dates, 2), 'dept':['A','B']*6, 'sal':np.random.randint(80,121, size=12)})\n",
    "df = df.sort_values('date')\n",
    "trend = df.groupby('dept').apply(lambda g: g.set_index('date')['sal'].rolling(3, min_periods=1).mean()).rename('sal_ma3').reset_index()\n",
    "print(trend.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### LAB 70: Delete Duplicate Phone Numbers\n",
    "**Goals:** `drop_duplicates` on column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'phone':['111','222','111','333']})\n",
    "print(df.drop_duplicates('phone'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Mock Interview (60 minutes)\n",
    "\n",
    "**1) What are the main differences between `merge`, `join`, and `concat`?**  \n",
    "*Answer:* `merge` performs SQL-style joins on columns or index; `join` is a convenience for index-based joins (or column-on-index); `concat` stacks objects along an axis (row-wise or column-wise), aligning by index/columns.\n",
    "\n",
    "**2) When should you prefer `map`/`replace`/`merge` for lookups?**  \n",
    "*Answer:* Small Series mapping → `map`; simple substitution → `replace`; relational lookup with many-to-one/one-to-many and extra columns → `merge`.\n",
    "\n",
    "**3) Explain `groupby(...).agg` vs `transform`.**  \n",
    "*Answer:* `agg` collapses groups to a reduced result; `transform` returns an output aligned with the original index, broadcasting per-group results back (e.g., z-scores, group-means subtraction).\n",
    "\n",
    "**4) How to detect and handle missing values robustly?**  \n",
    "*Answer:* Use `isna`/`notna`; choose strategies contextually (`fillna`, `dropna`, impute by group medians), preserve dtypes with `convert_dtypes`.\n",
    "\n",
    "**5) Vectorization vs `apply` vs Python loops?**  \n",
    "*Answer:* Prefer vectorized ops; `apply` row-wise is Python-level and slow; use `numexpr`, category types, and `merge`/`groupby` to avoid row loops.\n",
    "\n",
    "**6) Pitfalls with chained indexing?**  \n",
    "*Answer:* `df[df.x>0]['y']=...` can set on a copy. Prefer `.loc[mask, 'y']=...` to avoid `SettingWithCopyWarning`.\n",
    "\n",
    "**7) Wide↔Long reshaping difference between `pivot` and `melt`?**  \n",
    "*Answer:* `pivot` turns long → wide using index/columns/values, assumes uniqueness; `melt` collapses wide → long.\n",
    "\n",
    "**8) Time-series resample vs groupby?**  \n",
    "*Answer:* `resample` requires a DatetimeIndex and bins by time frequency; `groupby(pd.Grouper(freq=...))` can group by time-like keys on columns or index.\n",
    "\n",
    "**9) How to get second highest per group?**  \n",
    "*Answer:* Use `drop_duplicates`, `nlargest`, then `groupby('group')['value'].nlargest(2).groupby(level=0).nth(1)`, or sort and `cumcount`.\n",
    "\n",
    "**10) Memory optimizations?**  \n",
    "*Answer:* Use `Categorical` for low-cardinality strings, downcast numerics (`to_numeric(..., downcast='integer')`), read CSV with dtype dicts, chunked processing, and `usecols`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311 (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
